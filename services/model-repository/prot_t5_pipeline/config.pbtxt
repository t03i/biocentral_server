name: "prot_t5_pipeline"
platform: "ensemble"
max_batch_size: 8

input [
  {
    name: "sequences"
    data_type: TYPE_STRING
    dims: [ -1 ]
  }
]

output [
  {
    name: "embeddings"
    data_type: TYPE_FP16
    dims: [ -1, 1024 ]
  }
]

ensemble_scheduling {
  step [
    {
      model_name: "_internal_tokenizer"
      model_version: 1
      input_map {
        key: "sequences"
        value: "sequences"
      }
      output_map {
        key: "input_ids"
        value: "input_ids"
      }
      output_map {
        key: "attention_mask"
        value: "attention_mask"
      }
    },
    {
      model_name: "_internal_onnx"
      model_version: 1
      input_map {
        key: "input_ids"
        value: "input_ids"
      }
      input_map {
        key: "attention_mask"
        value: "attention_mask"
      }
      output_map {
        key: "last_hidden_state"
        value: "embeddings"
      }
    }
  ]
} 